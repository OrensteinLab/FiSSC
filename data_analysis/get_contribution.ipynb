{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['logs\\\\ABL_DROME_filter_log.csv', 'logs\\\\ACHA4_MOUSE_filter_log.csv', 'logs\\\\ANR17_HUMAN_filter_log.csv', 'logs\\\\CA2D3_MOUSE_filter_log.csv', 'logs\\\\CACB2_RABIT_filter_log.csv', 'logs\\\\CSKI1_MOUSE_filter_log.csv', 'logs\\\\DGLA_HUMAN_filter_log.csv', 'logs\\\\DOP1_HUMAN_filter_log.csv', 'logs\\\\GRIA2_filter_log.csv', 'logs\\\\IQEC1_HUMAN_filter_log.csv', 'logs\\\\K0513_MOUSE_filter_log.csv', 'logs\\\\KCNAS_DROME_filter_log.csv', 'logs\\\\MTUS2_HUMAN_filter_log.csv', 'logs\\\\PCLO_CHICK_filter_log.csv', 'logs\\\\PCLO_filter_log.csv', 'logs\\\\RIMS2_RAT_filter_log.csv', 'logs\\\\ROBO2_HUMAN_filter_log.csv', 'logs\\\\RUSC2_MOUSE_filter_log.csv', 'logs\\\\SCN1_HETBL_filter_log.csv', 'logs\\\\TRIM2_BOVIN_filter_log.csv', 'logs\\\\TWK7_CAEEL_filter_log.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "path = 'logs'\n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if f.endswith('.csv')]\n",
    "files = [os.path.join(path, f) for f in files]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contribution_per_step(file):\n",
    "    df = pd.read_csv(file)\n",
    "    # Track changes for each row in the dataframe\n",
    "    df['change_working'] = df['Working'].diff()\n",
    "    df['change_picked'] = df['Picked'].diff()\n",
    "    df['change_x_count'] = df['X count'].diff()\n",
    "\n",
    "    # Create new columns to store cumulative changes\n",
    "    df['cumulative_working'] = df['change_working']\n",
    "    df['cumulative_picked'] = df['change_picked']\n",
    "    df['cumulative_x_count'] = df['change_x_count']\n",
    "\n",
    "    # Iterate over the dataframe and apply the merging logic\n",
    "    for i in range(1, len(df)):\n",
    "        needs_to_merge = df.loc[i, 'Method'] in ['Pick Must Have Assignments', 'Merge Lonely Sequences', 'Assign Concensous for Isolated']\n",
    "        if needs_to_merge:\n",
    "            df.loc[i, 'cumulative_working'] += df.loc[i+1, 'cumulative_working']\n",
    "            df.loc[i, 'cumulative_picked'] += df.loc[i+1, 'cumulative_picked']\n",
    "            df.loc[i, 'cumulative_x_count'] += df.loc[i+1, 'cumulative_x_count']\n",
    "            df.loc[i+1, 'cumulative_working'] = 0\n",
    "            df.loc[i+1, 'cumulative_picked'] = 0\n",
    "            df.loc[i+1, 'cumulative_x_count'] = 0\n",
    "\n",
    "    # Get names of all methods\n",
    "    methods = df['Method'].unique()\n",
    "\n",
    "    # Make a dictionary that goes from method to change in each metric\n",
    "    method_to_change = {}\n",
    "    for method in methods:\n",
    "        method_df = df[df['Method'] == method]\n",
    "        method_to_change[method] = (\n",
    "            method_df['cumulative_working'].sum(),\n",
    "            method_df['cumulative_picked'].sum(),\n",
    "            method_df['cumulative_x_count'].sum()\n",
    "        )\n",
    "\n",
    "    return method_to_change\n",
    "\n",
    "def get_initial(file):\n",
    "    df = pd.read_csv(file)\n",
    "    initial_working = df.loc[0, 'Working']\n",
    "    initial_x_count = df.loc[0, 'X count']\n",
    "\n",
    "    return initial_working, initial_x_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working: 421238, Picked: 0, X count: 2875125 in logs\\ABL_DROME_filter_log.csv\n",
      "Working: 603862, Picked: 0, X count: 3881367 in logs\\ACHA4_MOUSE_filter_log.csv\n",
      "Working: 242745, Picked: 0, X count: 1709832 in logs\\ANR17_HUMAN_filter_log.csv\n",
      "Working: 316931, Picked: 0, X count: 1148215 in logs\\CA2D3_MOUSE_filter_log.csv\n",
      "Working: 379584, Picked: 0, X count: 1742568 in logs\\CACB2_RABIT_filter_log.csv\n",
      "Working: 759863, Picked: 0, X count: 9300973 in logs\\CSKI1_MOUSE_filter_log.csv\n",
      "Working: 309182, Picked: 0, X count: 2693960 in logs\\DGLA_HUMAN_filter_log.csv\n",
      "Working: 483561, Picked: 0, X count: 3453449 in logs\\DOP1_HUMAN_filter_log.csv\n",
      "Working: 52953, Picked: 0, X count: 960482 in logs\\GRIA2_filter_log.csv\n",
      "Working: 536053, Picked: 0, X count: 4487167 in logs\\IQEC1_HUMAN_filter_log.csv\n",
      "Working: 490892, Picked: 0, X count: 1748602 in logs\\K0513_MOUSE_filter_log.csv\n",
      "Working: 250919, Picked: 0, X count: 1374529 in logs\\KCNAS_DROME_filter_log.csv\n",
      "Working: 588768, Picked: 0, X count: 3854901 in logs\\MTUS2_HUMAN_filter_log.csv\n",
      "Working: 632294, Picked: 0, X count: 6653920 in logs\\PCLO_CHICK_filter_log.csv\n",
      "Working: 52619, Picked: 0, X count: 1068125 in logs\\PCLO_filter_log.csv\n",
      "Working: 638769, Picked: 0, X count: 6554846 in logs\\RIMS2_RAT_filter_log.csv\n",
      "Working: 1040589, Picked: 0, X count: 9858534 in logs\\ROBO2_HUMAN_filter_log.csv\n",
      "Working: 212926, Picked: 0, X count: 1051278 in logs\\RUSC2_MOUSE_filter_log.csv\n",
      "Working: 333336, Picked: 0, X count: 3473784 in logs\\SCN1_HETBL_filter_log.csv\n",
      "Working: 189297, Picked: 0, X count: 1235089 in logs\\TRIM2_BOVIN_filter_log.csv\n",
      "Working: 510909, Picked: 0, X count: 2974417 in logs\\TWK7_CAEEL_filter_log.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    working= df['Working'].iloc[0]\n",
    "    picked= df['Picked'].iloc[0]\n",
    "    x_count= df['X count'].iloc[0]\n",
    "    print(f'Working: {working}, Picked: {picked}, X count: {x_count} in {file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_pie_charts(method_to_change, thresholds=[5, 5, 5], show_legend=True, font_size=10, legend_font_size=12, custom_names=None, initial_working=None, initial_x_count=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Creates multiple pie charts from the method_to_change dictionary and arranges them side by side.\n",
    "\n",
    "    Parameters:\n",
    "    - method_to_change (dict): Dictionary with methods as keys and tuples of changes as values.\n",
    "    - thresholds (list of floats): Percentage thresholds below which percentages are not shown.\n",
    "    - show_legend (bool): Whether to show the legend or not.\n",
    "    - font_size (int): Font size for the pie chart labels.\n",
    "    - legend_font_size (int): Font size for the legend text.\n",
    "    - custom_names (dict): Dictionary to map original method names to custom names for the legend.\n",
    "    - total (float): The total value that the pie chart should represent. If provided, the difference will be labeled as \"Uncovered\".\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    method_names = ['Working', 'Picked', 'X Count']\n",
    "\n",
    "    # Generate a color map for each label\n",
    "    labels = list(method_to_change.keys())\n",
    "    colors = list(mcolors.TABLEAU_COLORS.keys())\n",
    "    color_map = {label: colors[i % len(colors)] for i, label in enumerate(labels)}\n",
    "    color_map['Uncovered'] = colors[(len(labels) + 1) % len(colors)]  # Add \"Uncovered\" to color map\n",
    "    #color_map['Leftover'] = colors[(len(labels) + 2) % len(colors)]  # Add \"Leftover\" to color map\n",
    "    color_map['Leftover'] = colors[(len(labels) + 1) % len(colors)]  # Add \"Uncovered\" to color map but with the same color as \"Uncovered\"\n",
    "\n",
    "\n",
    "    for i, method_n in enumerate([0, 2, 1]):\n",
    "        # Extract labels and sizes\n",
    "        if method_n in [0, 2]:\n",
    "            sizes = [-method_to_change[method][method_n] for method in method_to_change]\n",
    "        else:\n",
    "            sizes = [method_to_change[method][method_n] for method in method_to_change]\n",
    "        \n",
    "        total_size = sum(sizes)\n",
    "        sizes_with_labels = [(size, label) for size, label in zip(sizes, labels)]\n",
    "        \n",
    "        # Filter out slices that round to 0.0%\n",
    "        filtered_sizes, filtered_labels = zip(\n",
    "            *[(size, label) for size, label in sizes_with_labels if size != 0]\n",
    "        )\n",
    "        \n",
    "        # If total is provided and sizes don't add up to total, add \"Uncovered\" slice\n",
    "        if method_n == 0 and initial_working is not None and total_size < initial_working:\n",
    "            uncovered_size = initial_working - total_size\n",
    "            filtered_sizes = list(filtered_sizes) + [uncovered_size]\n",
    "            filtered_labels = list(filtered_labels) + ['Uncovered']\n",
    "\n",
    "        if method_n == 2 and initial_x_count is not None and total_size < initial_x_count:\n",
    "            uncovered_size = initial_x_count - total_size\n",
    "            filtered_sizes = list(filtered_sizes) + [uncovered_size]\n",
    "            filtered_labels = list(filtered_labels) + ['Leftover']\n",
    "        \n",
    "        # Create pie chart with consistent colors\n",
    "        pie_colors = [color_map[label] for label in filtered_labels]\n",
    "        \n",
    "        wedges, texts, autotexts = axes[i].pie(\n",
    "            filtered_sizes, labels=None, autopct=lambda p: f'{p:.1f}%' if p >= thresholds[i] else '', startangle=140, colors=pie_colors,\n",
    "            textprops={'fontsize': font_size}, pctdistance=0.8\n",
    "        )\n",
    "\n",
    "        axes[i].axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "    # Optionally add a common legend\n",
    "    if show_legend:\n",
    "        # Apply custom names to labels if provided\n",
    "        if custom_names:\n",
    "            formatted_labels = [custom_names.get(label, label) for label in list(set(labels) - set(['Initial'])) + ['Uncovered', 'Leftover']]\n",
    "        else:\n",
    "            formatted_labels = [' '.join([word.lower() if idx > 0 else word for idx, word in enumerate(label.split())]) for label in list(set(labels) - set(['Initial'])) + ['Uncovered', 'Leftover']]\n",
    "        \n",
    "        handles = [plt.Line2D([0], [0], color=color_map[label], marker='o', linestyle='') for label in list(set(labels) - set(['Initial'])) + ['Uncovered', 'Leftover']]\n",
    "        fig.legend(handles, formatted_labels, title=None, loc=\"center right\", bbox_to_anchor=(0.95, 1.3), ncol=2, prop={'size': legend_font_size})\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_names = {\n",
    "    'Pick Must Have Assignments': 'Adding sequence assignments that cover multiple reads',\n",
    "    'Merge Lonely Sequences': 'Merging reads which agree with only one other reads',\n",
    "    'Apply Local Concensous': 'Assigning local consensus',\n",
    "    'Assign Concensous for Isolated': 'Assigning consensus for isolated reads',\n",
    "    'Update Knowns': 'Adding non-degenerate reads',\n",
    "    'Remove Less Specific': 'Removing less-specific reads',\n",
    "    'Others': 'Other'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Initial': (0.0, 0.0, 0.0), 'Update Knowns': (-4627.0, 160.0, -85136.0), 'Remove Less Specific': (-17878.0, 0.0, -355964.0), 'Pick Must Have Assignments': (-712.0, 165.0, -5960.0), 'Merge Lonely Sequences': (-2193.0, 101.0, -61654.0), 'Assign Concensous for Isolated': (-6745.0, 6745.0, -83775.0), 'Apply Local Concensous': (0.0, 0.0, -33590.0)}\n",
      "{'Initial': (0.0, 0.0, 0.0), 'Update Knowns': (-4506.0, 162.0, -94443.0), 'Remove Less Specific': (-13276.0, 0.0, -304336.0), 'Pick Must Have Assignments': (-204.0, 67.0, -1584.0), 'Merge Lonely Sequences': (-4295.0, 90.0, -145139.0), 'Assign Concensous for Isolated': (-24868.0, 24868.0, -360260.0), 'Apply Local Concensous': (0.0, 0.0, -69315.0)}\n"
     ]
    }
   ],
   "source": [
    "method_to_change = get_contribution_per_step('logs\\\\GRIA2_filter_log.csv')\n",
    "initial_working, initial_x_count = get_initial('logs\\\\GRIA2_filter_log.csv')\n",
    "print(method_to_change)\n",
    "create_pie_charts(method_to_change, thresholds=[3, 3, 3], show_legend=False, custom_names=custom_names, font_size=22, legend_font_size=20, initial_working=initial_working, initial_x_count=initial_x_count, save_path='GRIA2_filter.svg')\n",
    "#create_pie_charts(method_to_change, thresholds=[3, 3, 3], show_legend=True, custom_names=custom_names, font_size=22, legend_font_size=20, initial_working=initial_working, initial_x_count=initial_x_count)\n",
    "\n",
    "method_to_change = get_contribution_per_step('logs\\\\PCLO_filter_log.csv')\n",
    "initial_working, initial_x_count = get_initial('logs\\\\PCLO_filter_log.csv')\n",
    "create_pie_charts(method_to_change, thresholds=[3, 3, 3], show_legend=False, font_size=22,initial_working=initial_working, initial_x_count=initial_x_count, save_path='PCLO_filter.svg')\n",
    "print(method_to_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs\\TRIM2_BOVIN_filter_log.csv\n",
      "logs\\TWK7_CAEEL_filter_log.csv\n",
      "logs\\PCLO_CHICK_filter_log.csv\n",
      "logs\\ABL_DROME_filter_log.csv\n",
      "logs\\KCNAS_DROME_filter_log.csv\n",
      "logs\\SCN1_HETBL_filter_log.csv\n",
      "logs\\ANR17_HUMAN_filter_log.csv\n",
      "logs\\DGLA_HUMAN_filter_log.csv\n",
      "logs\\DOP1_HUMAN_filter_log.csv\n",
      "logs\\IQEC1_HUMAN_filter_log.csv\n",
      "logs\\MTUS2_HUMAN_filter_log.csv\n",
      "logs\\ROBO2_HUMAN_filter_log.csv\n",
      "logs\\ACHA4_MOUSE_filter_log.csv\n",
      "logs\\CA2D3_MOUSE_filter_log.csv\n",
      "logs\\CSKI1_MOUSE_filter_log.csv\n",
      "logs\\K0513_MOUSE_filter_log.csv\n",
      "logs\\RUSC2_MOUSE_filter_log.csv\n",
      "logs\\CACB2_RABIT_filter_log.csv\n",
      "logs\\RIMS2_RAT_filter_log.csv\n"
     ]
    }
   ],
   "source": [
    "short_reads = list(set(files)-  set(['logs\\\\GRIA2_filter_log.csv', 'logs\\\\PCLO_filter_log.csv']))\n",
    "def sorting_key(x):\n",
    "    species = x.split('_')[1]\n",
    "    name = x.split('_')[0].split('\\\\')[1]\n",
    "    return (species, name)\n",
    "\n",
    "sorted_short_reads = sorted(short_reads, key=sorting_key)\n",
    "#print(sorted_short_reads)\n",
    "\n",
    "\n",
    "for i, file in enumerate(sorted_short_reads):\n",
    "    method_to_change = get_contribution_per_step(file)\n",
    "    initial_working, initial_x_count = get_initial(file)\n",
    "    print(file)\n",
    "    #print(method_to_change)\n",
    "    create_pie_charts(method_to_change, thresholds=[5,5, 5], show_legend=(i==0), save_path=f'plots/{i}.svg', custom_names=custom_names, font_size=22, legend_font_size=18, initial_working=initial_working, initial_x_count=initial_x_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
